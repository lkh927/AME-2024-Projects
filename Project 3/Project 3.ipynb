{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AME project 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Racial differences in police use of force\n",
    "\n",
    "The goal of this project is to investigate whether there are racial differences in police use of force. We will analyse this issue based on three different binary response models: Linear Probaility Model (LPM), the Probit model, and the Logit model.\n",
    "Binary response models are relevant when the dependent variable $y$ has two possible outcomes, \n",
    "e.g., $y=1$ if a police encounter resulted in any use of force by the police officer(s), and $y=0$ if it does not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "The binary response model assumes that the data generating process is \n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_i^* &= \\mathbf{x}_i \\boldsymbol{\\beta} + u_i, \\\\ \n",
    "y_i   &= \\mathbf{1}(y_i^* > 0), \n",
    "\\end{aligned}\n",
    "$$\n",
    "where $u_i$ are distributed IID according to some cdf. $G$. \n",
    "\n",
    "In the lectures, it is shown that\n",
    "$$ p_i \\equiv \\Pr(y_i = 1| \\mathbf{x}_i) = G(\\mathbf{x}_i \\boldsymbol{\\beta}). $$ \n",
    "\n",
    "Since $y_i$ (conditioning on $\\mathbf{x}_i$) is Bernoulli-distributed with parameter $p_i$, its log-likelihood function is \n",
    "$$\n",
    "\\ell_i(\\theta) \n",
    "               = \\mathrm{1}(y_i = 1) \\log[ G(\\mathbf{x}_i \\boldsymbol{\\beta}) ]\n",
    "               + \\mathrm{1}(y_i = 0) \\log[1 - G(\\mathbf{x}_i \\boldsymbol{\\beta})]\n",
    "$$\n",
    "\n",
    "Estimation is then conducted by maximum likelihood, \n",
    "$$ \\hat{\\boldsymbol{\\theta}} = \\arg\\max_\\theta \\frac{1}{N} \\sum_{i=1}^N \\ell_i (\\theta), $$ \n",
    "which can be implemented as a minimizer in the usual $M$-framework with $q(\\theta, y_i, x_i) = -\\ell_i(\\theta)$, and then minimizing $Q(\\theta) = N^{-1} \\sum_i q(\\theta, y_i, x_i)$. \n",
    "\n",
    "We will consider two models: \n",
    "1. Probit: when $G$ is the standard normal CDF \n",
    "2. Logit: when $G$ is the standard logistic CDF. \n",
    "\n",
    "And we will be comparing them to OLS (which is called the Linear Probability Model, LPM, in a case like this where $y_i$ is binary). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from sys import path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "sns.set_theme()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import estimation as est \n",
    "import LinearModel as lm\n",
    "import probit\n",
    "import logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting and adjusting data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contains 3799 rows (encounters) and 19 columns (variables).\n"
     ]
    }
   ],
   "source": [
    "dat = pd.read_csv('ppcs_cc.csv')\n",
    "print(f'The data contains {dat.shape[0]} rows (encounters) and {dat.shape[1]} columns (variables).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sblack        shisp       swhite       sother        smale  \\\n",
      "count  3799.000000  3799.000000  3799.000000  3799.000000  3799.000000   \n",
      "mean      0.110555     0.101606     0.739142     0.048697     0.529613   \n",
      "std       0.313622     0.302169     0.439160     0.215262     0.499188   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     1.000000     0.000000     1.000000   \n",
      "75%       0.000000     0.000000     1.000000     0.000000     1.000000   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "              sage        sempl      sincome         spop      daytime  \\\n",
      "count  3799.000000  3799.000000  3799.000000  3799.000000  3799.000000   \n",
      "mean     41.010003     0.695446     2.164780     1.362727     0.666491   \n",
      "std      16.146916     0.460279     0.848262     0.765598     0.471529   \n",
      "min      16.000000     0.000000     1.000000     1.000000     0.000000   \n",
      "25%      27.000000     0.000000     1.000000     1.000000     0.000000   \n",
      "50%      40.000000     1.000000     2.000000     1.000000     1.000000   \n",
      "75%      52.000000     1.000000     3.000000     1.000000     1.000000   \n",
      "max      90.000000     1.000000     3.000000     4.000000     1.000000   \n",
      "\n",
      "       inctype_lin    omajblack     omajhisp    omajwhite    omajother  \\\n",
      "count  3799.000000  3799.000000  3799.000000  3799.000000  3799.000000   \n",
      "mean      1.958410     0.060805     0.023954     0.903659     0.011582   \n",
      "std       0.199676     0.239005     0.152925     0.295097     0.107009   \n",
      "min       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       2.000000     0.000000     0.000000     1.000000     0.000000   \n",
      "50%       2.000000     0.000000     0.000000     1.000000     0.000000   \n",
      "75%       2.000000     0.000000     0.000000     1.000000     0.000000   \n",
      "max       2.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "       osplit    sbehavior    year  anyuseofforce_coded  \n",
      "count  3799.0  3799.000000  3799.0          3799.000000  \n",
      "mean      0.0     0.065017  2011.0             0.005001  \n",
      "std       0.0     0.246589     0.0             0.070552  \n",
      "min       0.0     0.000000  2011.0             0.000000  \n",
      "25%       0.0     0.000000  2011.0             0.000000  \n",
      "50%       0.0     0.000000  2011.0             0.000000  \n",
      "75%       0.0     0.000000  2011.0             0.000000  \n",
      "max       0.0     1.000000  2011.0             1.000000  \n",
      "Possible values of each variable:\n",
      "sblack: [1 0]\n",
      "shisp: [0 1]\n",
      "swhite: [0 1]\n",
      "sother: [0 1]\n",
      "smale: [1 0]\n",
      "sage: [18 20 22 29 28 26 25 30 41 44 47 48 52 16 17 19 21 24 23 27 31 32 33 34\n",
      " 35 39 37 36 40 43 42 46 45 53 50 51 54 59 57 58 55 56 61 60 63 64 62 69\n",
      " 68 66 71 72 90 78 83 38 49 65 70 73 74 85 77 81 80 76 67 79 86 75 84 82\n",
      " 88 89]\n",
      "sempl: [0 1]\n",
      "sincome: [1 2 3]\n",
      "spop: [1 4 3 2]\n",
      "daytime: [1 0]\n",
      "inctype_lin: [2 1]\n",
      "omajblack: [0 1]\n",
      "omajhisp: [0 1]\n",
      "omajwhite: [1 0]\n",
      "omajother: [0 1]\n",
      "osplit: [0]\n",
      "sbehavior: [0 1]\n",
      "year: [2011]\n",
      "anyuseofforce_coded: [0 1]\n"
     ]
    }
   ],
   "source": [
    "#Summary statistics for variables  \n",
    "print(dat.describe())\n",
    "\n",
    "#Possible values of each variable\n",
    "print('Possible values of each variable:')\n",
    "for col in dat.columns:\n",
    "    print(f'{col}: {dat[col].unique()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data now contains 3799 rows (encounters) and 20 columns (variables).\n",
      "White subjects in data: 2808\n",
      "Force were used against 9 of the white subjects\n",
      "Black subjects in data: 420\n",
      "Force were used against 3 of the black subjects\n",
      "Hispanic subjects in data: 386\n",
      "Force were used against 6 of the Hispanic subjects\n",
      "Other subjects in data: 185\n",
      "Force were used against 1 of the other subjects\n"
     ]
    }
   ],
   "source": [
    "#Exclude the variables with zero variance\n",
    "dat = dat.drop(columns=['osplit', 'year'])\n",
    "\n",
    "#Transform the variables 'sincome', 'spop', 'inctype_lin' to dummy variables\n",
    "dat = pd.get_dummies(dat, columns=['inctype_lin', 'sincome', 'spop'], drop_first=True, dtype=int)\n",
    "\n",
    "#Adjust names of new dummies\n",
    "dat.rename(columns={'inctype_lin_2': 'traffic_stop', 'sincome_2': 'sincome_20-50', 'sincome_3': 'sincome_above50', 'spop_2': 'spop_100-499', 'spop_3':'spop_500-999', 'spop_4': 'spop_above1000' }, inplace=True)\n",
    "\n",
    "print(f'The data now contains {dat.shape[0]} rows (encounters) and {dat.shape[1]} columns (variables).')\n",
    "\n",
    "#divide age by 10\n",
    "dat['sage'] = dat['sage']/10\n",
    "\n",
    "#Adding constant and squared age\n",
    "dat['const'] = np.ones((N,))\n",
    "dat['sagesq'] = dat['sage'] * dat['sage']\n",
    "\n",
    "#dimension of the data\n",
    "N = dat.shape[0]\n",
    "\n",
    "#Count the number of times swhite, sblack, shisp, sother is one when anyuseofforce_coded is one\n",
    "white_force = dat['swhite'] * dat['anyuseofforce_coded']\n",
    "black_force = dat['sblack'] * dat['anyuseofforce_coded']\n",
    "hisp_force = dat['shisp'] * dat['anyuseofforce_coded']\n",
    "other_force = dat['sother'] * dat['anyuseofforce_coded']\n",
    "\n",
    "white=dat['swhite'].sum()\n",
    "black=dat['sblack'].sum()\n",
    "hisp=dat['shisp'].sum()\n",
    "other=dat['sother'].sum()\n",
    "\n",
    "#print\n",
    "print(f'White subjects in data: {white}')\n",
    "print(f'Force were used against {white_force.sum()} of the white subjects')\n",
    "print(f'Black subjects in data: {black}')\n",
    "print(f'Force were used against {black_force.sum()} of the black subjects')\n",
    "print(f'Hispanic subjects in data: {hisp}')\n",
    "print(f'Force were used against {hisp_force.sum()} of the Hispanic subjects')\n",
    "print(f'Other subjects in data: {other}')\n",
    "print(f'Force were used against {other_force.sum()} of the other subjects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare labels\n",
    "y_lab = 'anyuseofforce_coded' # dependent variable\n",
    "x_lab = ['const', \n",
    "         'sblack', 'shisp','sother', #swhite is the reference category\n",
    "         'smale',  'sbehavior',\n",
    "         'sage', 'sagesq',\n",
    "         'sincome_20-50', 'sincome_above50', #sincome_0-20 is the reference category\n",
    "         'omajwhite',# the reference category is that the officers belong to a racial minority ('omajblack', 'omajhisp', 'omajother') \n",
    "         'daytime', 'traffic_stop'\n",
    "        ]\n",
    "\n",
    "# reorder columns \n",
    "data = dat[[y_lab] + x_lab].copy()\n",
    "\n",
    "y = data[y_lab].values\n",
    "x = data[x_lab].values\n",
    "K = x.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LPM results\n",
      "Dependent variable: anyuseofforce_coded\n",
      "\n",
      "R2 = 0.030\n",
      "sigma2 = nan\n"
     ]
    }
   ],
   "source": [
    "ols_results = lm.estimate(y, x, robust_se=True)\n",
    "ols_tab = lm.print_table((y_lab, x_lab), ols_results, title='LPM results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023516\n",
      "         Iterations: 106\n",
      "         Function evaluations: 1722\n",
      "         Gradient evaluations: 123\n",
      "Optimizer succeded after 106 iter. (1722 func. evals.). Final criterion:  0.02352.\n",
      "Probit, y = anyuseofforce_coded\n"
     ]
    }
   ],
   "source": [
    "beta0_probit = probit.starting_values(y, x)\n",
    "\n",
    "probit_results = est.estimate(probit.q, beta0_probit, y, x)\n",
    "probit_tab = est.print_table(x_lab, probit_results, title=f'Probit, y = {y_lab}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023638\n",
      "         Iterations: 125\n",
      "         Function evaluations: 1988\n",
      "         Gradient evaluations: 142\n",
      "Optimizer succeded after 125 iter. (1988 func. evals.). Final criterion:  0.02364.\n",
      "Logit, y = anyuseofforce_coded\n"
     ]
    }
   ],
   "source": [
    "beta0_logit = logit.starting_values(y, x)\n",
    "\n",
    "logit_results = est.estimate(logit.q, beta0_logit, y, x)\n",
    "logit_tab = est.print_table(x_lab, logit_results, title=f'Logit, y = {y_lab}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LPM coef</th>\n",
       "      <th>LPM se</th>\n",
       "      <th>LPM t</th>\n",
       "      <th>Probit coef</th>\n",
       "      <th>Probit se</th>\n",
       "      <th>Probit t</th>\n",
       "      <th>Logit coef</th>\n",
       "      <th>Logit se</th>\n",
       "      <th>Logit t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>2.0776</td>\n",
       "      <td>-3.1622</td>\n",
       "      <td>1.9742</td>\n",
       "      <td>-1.6018</td>\n",
       "      <td>-7.0497</td>\n",
       "      <td>4.3546</td>\n",
       "      <td>-1.6189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sblack</th>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.7953</td>\n",
       "      <td>0.2928</td>\n",
       "      <td>0.3703</td>\n",
       "      <td>0.7908</td>\n",
       "      <td>0.6686</td>\n",
       "      <td>0.8705</td>\n",
       "      <td>0.7681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shisp</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>1.7754</td>\n",
       "      <td>0.5404</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>1.7431</td>\n",
       "      <td>1.3226</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>1.9595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sother</th>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.1237</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.6589</td>\n",
       "      <td>0.3447</td>\n",
       "      <td>0.3078</td>\n",
       "      <td>1.7987</td>\n",
       "      <td>0.1711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smale</th>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>0.4778</td>\n",
       "      <td>0.4020</td>\n",
       "      <td>1.1886</td>\n",
       "      <td>1.0375</td>\n",
       "      <td>0.8933</td>\n",
       "      <td>1.1614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbehavior</th>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>2.9058</td>\n",
       "      <td>1.0742</td>\n",
       "      <td>0.3917</td>\n",
       "      <td>2.7423</td>\n",
       "      <td>2.5830</td>\n",
       "      <td>0.8447</td>\n",
       "      <td>3.0580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sage</th>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>-0.5311</td>\n",
       "      <td>0.2335</td>\n",
       "      <td>0.7541</td>\n",
       "      <td>0.3097</td>\n",
       "      <td>1.0070</td>\n",
       "      <td>1.7503</td>\n",
       "      <td>0.5753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sagesq</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>-0.0456</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>-0.4822</td>\n",
       "      <td>-0.1826</td>\n",
       "      <td>0.2313</td>\n",
       "      <td>-0.7894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sincome_20-50</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.2568</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.4507</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.9790</td>\n",
       "      <td>0.1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sincome_above50</th>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.3239</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.4037</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.8497</td>\n",
       "      <td>0.1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omajwhite</th>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>1.3150</td>\n",
       "      <td>0.4672</td>\n",
       "      <td>0.8133</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>0.9272</td>\n",
       "      <td>1.6907</td>\n",
       "      <td>0.5485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daytime</th>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-0.5503</td>\n",
       "      <td>-0.1501</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>-0.4874</td>\n",
       "      <td>-0.3323</td>\n",
       "      <td>0.6879</td>\n",
       "      <td>-0.4831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traffic_stop</th>\n",
       "      <td>-0.0297</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>-1.9764</td>\n",
       "      <td>-0.8137</td>\n",
       "      <td>0.3232</td>\n",
       "      <td>-2.5174</td>\n",
       "      <td>-1.9275</td>\n",
       "      <td>0.6893</td>\n",
       "      <td>-2.7963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 LPM coef  LPM se   LPM t  Probit coef  Probit se  Probit t  \\\n",
       "const              0.0304  0.0146  2.0776      -3.1622     1.9742   -1.6018   \n",
       "sblack             0.0036  0.0045  0.7953       0.2928     0.3703    0.7908   \n",
       "shisp              0.0108  0.0061  1.7754       0.5404     0.3100    1.7431   \n",
       "sother             0.0007  0.0057  0.1237       0.2271     0.6589    0.3447   \n",
       "smale              0.0037  0.0022  1.6704       0.4778     0.4020    1.1886   \n",
       "sbehavior          0.0357  0.0123  2.9058       1.0742     0.3917    2.7423   \n",
       "sage              -0.0016  0.0029 -0.5311       0.2335     0.7541    0.3097   \n",
       "sagesq             0.0000  0.0003  0.0918      -0.0456     0.0945   -0.4822   \n",
       "sincome_20-50      0.0008  0.0033  0.2568       0.0582     0.4507    0.1291   \n",
       "sincome_above50    0.0009  0.0027  0.3239       0.0874     0.4037    0.2165   \n",
       "omajwhite          0.0040  0.0030  1.3150       0.4672     0.8133    0.5745   \n",
       "daytime           -0.0016  0.0028 -0.5503      -0.1501     0.3080   -0.4874   \n",
       "traffic_stop      -0.0297  0.0150 -1.9764      -0.8137     0.3232   -2.5174   \n",
       "\n",
       "                 Logit coef  Logit se  Logit t  \n",
       "const               -7.0497    4.3546  -1.6189  \n",
       "sblack               0.6686    0.8705   0.7681  \n",
       "shisp                1.3226    0.6750   1.9595  \n",
       "sother               0.3078    1.7987   0.1711  \n",
       "smale                1.0375    0.8933   1.1614  \n",
       "sbehavior            2.5830    0.8447   3.0580  \n",
       "sage                 1.0070    1.7503   0.5753  \n",
       "sagesq              -0.1826    0.2313  -0.7894  \n",
       "sincome_20-50        0.1949    0.9790   0.1991  \n",
       "sincome_above50      0.1050    0.8497   0.1236  \n",
       "omajwhite            0.9272    1.6907   0.5485  \n",
       "daytime             -0.3323    0.6879  -0.4831  \n",
       "traffic_stop        -1.9275    0.6893  -2.7963  "
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Table with results for all models\n",
    "results = pd.concat([ols_tab, probit_tab, logit_tab], axis=1)\n",
    "\n",
    "#Adjusting column names\n",
    "results.columns = ['LPM coef', 'LPM se', 'LPM t', 'Probit coef', 'Probit se', 'Probit t', 'Logit coef', 'Logit se', 'Logit t']\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      " & LPM coef & LPM se & LPM t & Probit coef & Probit se & Probit t & Logit coef & Logit se & Logit t \\\\\n",
      "\\midrule\n",
      "const & 0.03 & 0.01 & 2.08 & -3.16 & 1.97 & -1.60 & -7.05 & 4.35 & -1.62 \\\\\n",
      "sblack & 0.00 & 0.00 & 0.80 & 0.29 & 0.37 & 0.79 & 0.67 & 0.87 & 0.77 \\\\\n",
      "shisp & 0.01 & 0.01 & 1.78 & 0.54 & 0.31 & 1.74 & 1.32 & 0.68 & 1.96 \\\\\n",
      "sother & 0.00 & 0.01 & 0.12 & 0.23 & 0.66 & 0.34 & 0.31 & 1.80 & 0.17 \\\\\n",
      "smale & 0.00 & 0.00 & 1.67 & 0.48 & 0.40 & 1.19 & 1.04 & 0.89 & 1.16 \\\\\n",
      "sbehavior & 0.04 & 0.01 & 2.91 & 1.07 & 0.39 & 2.74 & 2.58 & 0.84 & 3.06 \\\\\n",
      "sage & -0.00 & 0.00 & -0.53 & 0.23 & 0.75 & 0.31 & 1.01 & 1.75 & 0.58 \\\\\n",
      "sagesq & 0.00 & 0.00 & 0.09 & -0.05 & 0.09 & -0.48 & -0.18 & 0.23 & -0.79 \\\\\n",
      "sincome_20-50 & 0.00 & 0.00 & 0.26 & 0.06 & 0.45 & 0.13 & 0.19 & 0.98 & 0.20 \\\\\n",
      "sincome_above50 & 0.00 & 0.00 & 0.32 & 0.09 & 0.40 & 0.22 & 0.10 & 0.85 & 0.12 \\\\\n",
      "omajwhite & 0.00 & 0.00 & 1.31 & 0.47 & 0.81 & 0.57 & 0.93 & 1.69 & 0.55 \\\\\n",
      "daytime & -0.00 & 0.00 & -0.55 & -0.15 & 0.31 & -0.49 & -0.33 & 0.69 & -0.48 \\\\\n",
      "traffic_stop & -0.03 & 0.01 & -1.98 & -0.81 & 0.32 & -2.52 & -1.93 & 0.69 & -2.80 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.to_latex(results, float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Significance of racial differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above models we use \"swhite\" as the baseline race category allowing us to make inference about the difference between being a white subject or a black/hispanic/other subject. We now explore the differences between black and hispanic subjects, black and other subjects, and hispanic and other subjects. \n",
    "\n",
    "We base the coefficient differences on the estimates from the above models, and base the standard errors of the differences on the delta method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DELTA METHOD\n",
    "\n",
    "# Gradient vector\n",
    "x_black = np.zeros(K)\n",
    "x_hisp = np.zeros(K)\n",
    "x_other = np.zeros(K)\n",
    "x_black[1] = 1\n",
    "x_hisp[2] = 1\n",
    "x_other[3] = 1\n",
    "\n",
    "grad_hisp_black = x_hisp - x_black\n",
    "grad_other_black = x_other - x_black\n",
    "grad_other_hisp = x_other - x_hisp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_se(grad, cov):\n",
    "    cov_me = grad@cov@grad.T\n",
    "    return np.sqrt((cov_me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD ERRORS FOR DIFFERENCES\n",
    "\n",
    "#LPM\n",
    "lpm_se_hisp_black = get_se(grad_hisp_black, ols_results['cov'])\n",
    "lpm_se_other_black = get_se(grad_other_black, ols_results['cov'])\n",
    "lpm_se_other_hisp = get_se(grad_other_hisp, ols_results['cov'])\n",
    "\n",
    "#Probit\n",
    "probit_se_hisp_black = get_se(grad_hisp_black, probit_results['cov'])\n",
    "probit_se_other_black = get_se(grad_other_black, probit_results['cov'])\n",
    "probit_se_other_hisp = get_se(grad_other_hisp, probit_results['cov'])\n",
    "\n",
    "#Logit\n",
    "logit_se_hisp_black = get_se(grad_hisp_black, logit_results['cov'])\n",
    "logit_se_other_black = get_se(grad_other_black, logit_results['cov'])\n",
    "logit_se_other_hisp = get_se(grad_other_hisp, logit_results['cov'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COEFFICIENTS FOR DIFFERENCES\n",
    "\n",
    "#LPM\n",
    "lpm_coef_hisp_black = ols_results['b_hat'][2] - ols_results['b_hat'][1]\n",
    "lpm_coef_other_black = ols_results['b_hat'][3] - ols_results['b_hat'][1]\n",
    "lpm_coef_other_hisp = ols_results['b_hat'][3] - ols_results['b_hat'][2]\n",
    "\n",
    "#Probit\n",
    "probit_coef_hisp_black = probit_results['beta'][2] - probit_results['beta'][1]\n",
    "probit_coef_other_black = probit_results['beta'][3] - probit_results['beta'][1]\n",
    "probit_coef_other_hisp = probit_results['beta'][3] - probit_results['beta'][2]\n",
    "\n",
    "#Logit\n",
    "logit_coef_hisp_black = logit_results['beta'][2] - logit_results['beta'][1]\n",
    "logit_coef_other_black = logit_results['beta'][3] - logit_results['beta'][1]\n",
    "logit_coef_other_hisp = logit_results['beta'][3] - logit_results['beta'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LPM coef</th>\n",
       "      <th>LPM se</th>\n",
       "      <th>LPM t</th>\n",
       "      <th>Probit coef</th>\n",
       "      <th>Probit se</th>\n",
       "      <th>Probit t</th>\n",
       "      <th>Logit coef</th>\n",
       "      <th>Logit se</th>\n",
       "      <th>Logit t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hispanic-Black</th>\n",
       "      <td>0.007201</td>\n",
       "      <td>0.007428</td>\n",
       "      <td>0.969406</td>\n",
       "      <td>0.247519</td>\n",
       "      <td>0.467451</td>\n",
       "      <td>0.529507</td>\n",
       "      <td>0.654007</td>\n",
       "      <td>1.002226</td>\n",
       "      <td>0.652555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other-Black</th>\n",
       "      <td>-0.002882</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>-0.421276</td>\n",
       "      <td>-0.065736</td>\n",
       "      <td>0.739911</td>\n",
       "      <td>-0.088844</td>\n",
       "      <td>-0.360828</td>\n",
       "      <td>2.011861</td>\n",
       "      <td>-0.179350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other-Hispanic</th>\n",
       "      <td>-0.010083</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>-1.248334</td>\n",
       "      <td>-0.313255</td>\n",
       "      <td>0.731425</td>\n",
       "      <td>-0.428280</td>\n",
       "      <td>-1.014835</td>\n",
       "      <td>1.903583</td>\n",
       "      <td>-0.533119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                LPM coef    LPM se     LPM t  Probit coef  Probit se  \\\n",
       "Hispanic-Black  0.007201  0.007428  0.969406     0.247519   0.467451   \n",
       "Other-Black    -0.002882  0.006841 -0.421276    -0.065736   0.739911   \n",
       "Other-Hispanic -0.010083  0.008077 -1.248334    -0.313255   0.731425   \n",
       "\n",
       "                Probit t  Logit coef  Logit se   Logit t  \n",
       "Hispanic-Black  0.529507    0.654007  1.002226  0.652555  \n",
       "Other-Black    -0.088844   -0.360828  2.011861 -0.179350  \n",
       "Other-Hispanic -0.428280   -1.014835  1.903583 -0.533119  "
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print results in a table\n",
    "diff_table = pd.DataFrame({'LPM coef': [lpm_coef_hisp_black, lpm_coef_other_black, lpm_coef_other_hisp],\n",
    "                           'LPM se': [lpm_se_hisp_black, lpm_se_other_black, lpm_se_other_hisp],\n",
    "                           'LPM t': [lpm_coef_hisp_black/lpm_se_hisp_black, lpm_coef_other_black/lpm_se_other_black, lpm_coef_other_hisp/lpm_se_other_hisp],\n",
    "                           'Probit coef': [probit_coef_hisp_black, probit_coef_other_black, probit_coef_other_hisp],\n",
    "                           'Probit se': [probit_se_hisp_black, probit_se_other_black, probit_se_other_hisp],\n",
    "                           'Probit t': [probit_coef_hisp_black/probit_se_hisp_black, probit_coef_other_black/probit_se_other_black, probit_coef_other_hisp/probit_se_other_hisp],\n",
    "                           'Logit coef': [logit_coef_hisp_black, logit_coef_other_black, logit_coef_other_hisp],\n",
    "                           'Logit se': [logit_se_hisp_black, logit_se_other_black, logit_se_other_hisp],\n",
    "                           'Logit t': [logit_coef_hisp_black/logit_se_hisp_black, logit_coef_other_black/logit_se_other_black, logit_coef_other_hisp/logit_se_other_hisp]},       \n",
    "                            index=['Hispanic-Black', 'Other-Black', 'Other-Hispanic'])\n",
    "\n",
    "diff_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      " & LPM coef & LPM se & LPM t & Probit coef & Probit se & Probit t & Logit coef & Logit se & Logit t \\\\\n",
      "\\midrule\n",
      "Hispanic-Black & 0.01 & 0.01 & 0.97 & 0.25 & 0.47 & 0.53 & 0.65 & 1.00 & 0.65 \\\\\n",
      "Other-Black & -0.00 & 0.01 & -0.42 & -0.07 & 0.74 & -0.09 & -0.36 & 2.01 & -0.18 \\\\\n",
      "Other-Hispanic & -0.01 & 0.01 & -1.25 & -0.31 & 0.73 & -0.43 & -1.01 & 1.90 & -0.53 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.to_latex(diff_table, float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Partial Effect (APE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we only found slightly significant racial differences in the probability of policy use of force between white and hispanic subjects. Here we calculate the actual magnitude of this difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating two new datasets - one where all respondents are coded as white and one where all respondents are coded as Hispanic\n",
    "x_swhite = x.copy()\n",
    "x_swhite[:, x_lab.index('shisp')] = 0\n",
    "x_swhite[:, x_lab.index('sblack')] = 0\n",
    "x_swhite[:, x_lab.index('sother')] = 0\n",
    "\n",
    "x_shisp = x.copy()\n",
    "x_shisp[:, x_lab.index('shisp')] = 1\n",
    "x_shisp[:, x_lab.index('sblack')] = 0\n",
    "x_shisp[:, x_lab.index('sother')] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APE based on probit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Partial Effect of being Hispanic rather than white: 0.0083\n",
      "I.e the probability of the police using force is, on average, 0.83% higher if the subject is Hispanic rather than white.\n"
     ]
    }
   ],
   "source": [
    "PE_probit=probit.G(x_shisp @ probit_results['beta'])-probit.G(x_swhite @ probit_results['beta'])\n",
    "APE_probit=PE_probit.mean()\n",
    "print(f'Average Partial Effect of being Hispanic rather than white: {APE_probit:.4f}')\n",
    "print(f'I.e the probability of the police using force is, on average, {APE_probit*100:.2f}% higher if the subject is Hispanic rather than white.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APE based on logit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Partial Effect of being Hispanic rather than white: 0.0083\n",
      "I.e the probability of the police using force is, on average, 0.83% higher if the subject is Hispanic rather than white.\n"
     ]
    }
   ],
   "source": [
    "PE_logit=logit.G(x_shisp @ logit_results['beta'])-logit.G(x_swhite @ logit_results['beta'])\n",
    "APE_logit=PE_logit.mean()\n",
    "print(f'Average Partial Effect of being Hispanic rather than white: {APE_logit:.4f}')\n",
    "print(f'I.e the probability of the police using force is, on average, {APE_logit*100:.2f}% higher if the subject is Hispanic rather than white.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LPM</th>\n",
       "      <td>0.0108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Probit</th>\n",
       "      <td>0.0083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logit</th>\n",
       "      <td>0.0083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           APE\n",
       "LPM     0.0108\n",
       "Probit  0.0083\n",
       "Logit   0.0083"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print results \n",
    "APE_table = pd.DataFrame([ols_results['b_hat'][x_lab.index('shisp')], \n",
    "              APE_probit,\n",
    "                APE_logit],\n",
    "             index=['LPM', 'Probit', 'Logit'], columns=[f'APE']).round(4)\n",
    "APE_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      " & APE \\\\\n",
      "\\midrule\n",
      "LPM & 0.0108 \\\\\n",
      "Probit & 0.0083 \\\\\n",
      "Logit & 0.0083 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.to_latex(APE_table, float_format=\"%.4f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
