{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project 1: Linear Panel Data and Production Technology**\n",
    "\n",
    "By Emma Knippel, Anna Abildskov and Oscar Nyholm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**\n",
    "* [Setup](#toc0_)\n",
    "\n",
    "* [Introduction](#toc1_)   \n",
    "\n",
    "* [Read and clean data](#toc2_) \n",
    "\n",
    "* [FE estimation of $\\beta_K$ and $\\beta_L$](#toc3_)    \n",
    "\n",
    "* [Test for constant returns to scale](#toc4_)    \n",
    "\n",
    "* [Conclusion](#toc5_)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc0_'><a>[Setup](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from tabulate import tabulate\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import chi2\n",
    "\n",
    "#Supress Future Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#Import our py-file\n",
    "import Project_1 as pf\n",
    "\n",
    "# autoreload modules when code is run\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_'></a>[Introduction](#toc1_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- intro\n",
    "- intro\n",
    "- intro\n",
    "\n",
    "\n",
    "We are estimating parameters of a Cobb-Douglas production function of the form:\n",
    "$$\\begin{aligned}\n",
    "y_it = \\beta_kk_{it}+\\beta_Ll_{it}+v_{it},\n",
    "\\end{aligned}$$\n",
    "Where $v_{it} =\\ln A_{it}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_'></a>[Read and clean data](#toc2_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains `N = 441` firms observed over `T = 12` years, 1968-1979. There variables are: \n",
    "* `lcap`: Log of capital stock, $k_{it}$ \n",
    "* `lemp`: log of employment, $\\ell_{it}$ \n",
    "* `ldsa`: log of deflated sales, $y_{it}$\n",
    "* `year`: the calendar year of the observation, `year` $ = 1968, ..., 1979$, \n",
    "* `firmid`: anonymized indicator variable for the firm, $i = 1, ..., N$, with $N=441$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data and dropping all the even years, leaving us with only odd year-observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_years = pd.read_csv('firms.csv')\n",
    "data = df_all_years[df_all_years.year % 2 != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting data to numpy format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains data for 441 firms over 6 odd years\n"
     ]
    }
   ],
   "source": [
    "N = data.firmid.unique().size\n",
    "T = data.year.unique().size\n",
    "print(f'Data contains data for {N} firms over {T} odd years')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting data to numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.ldsa.values.reshape((N*T,1))\n",
    "const = np.ones((N*T,1))\n",
    "l = data.lemp.values.reshape((N*T,1))\n",
    "k = data.lcap.values.reshape((N*T,1))\n",
    "X = np.hstack([const, l, k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating label-vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_y = 'ldsa'\n",
    "label_x = ['lemp', 'lcap']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_'></a>[FE estimation of $\\beta_K$ and $\\beta_L$](#toc3_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When deciding which estimator to use for analysis of panel data (POLS, RE, FE, FD), the following aspects are relevant to consider:\n",
    "\n",
    "- xxx\n",
    "\n",
    "Based on this, it seem reasonable to proceed with the FE estimator. \n",
    "\n",
    "(here we should insert a description of the FE estimator (including the transformation matrix, Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Effects\n",
      "Dependent variable: ldsa\n",
      "\n",
      "        Beta      Se    t-values\n",
      "----  ------  ------  ----------\n",
      "lemp  0.7069  0.0202     35.0694\n",
      "lcap  0.1424  0.0180      7.9319\n",
      "R² = 0.468\n",
      "σ² = 0.016\n"
     ]
    }
   ],
   "source": [
    "Q_T = np.eye(T) - np.tile(1/T, (T, T)) \n",
    "\n",
    "y_demean = pf.perm(Q_T, y)\n",
    "x_demean = pf.perm(Q_T, X)\n",
    "\n",
    "fe_result = pf.estimate(y_demean, x_demean[:,1:3], T=T)  # We exclude the constant from the fixed effects estimation, as the given Cobb-Dougles production function does not include a constant term\n",
    "pf.print_table((label_y, label_x), fe_result, title=\"Fixed Effects\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_'></a>[Test for constant returns to scale](#toc4_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be shown [DO WE HAVE TO SHOW THIS?] that a Cobb Douglas production technology, yield a constant return to scale if the parameters of the production inputs (i.e. the betas) sum to unity. Specifically, the production technology specified in relation to this assignment, will yield constant returns to scale if $\\beta_K + \\beta_L = 1$. Based on an Wald test, we can test the hypothesis that this is true against the alternative, that it is not true.\n",
    "\n",
    "$H_0: \\beta_K + \\beta_L = 1$\n",
    "\n",
    "$H_1: \\beta_K + \\beta_L \\neq 1$\n",
    "\n",
    "The general Wald statistic is: \n",
    "\n",
    "$W:=(R\\widehat{\\beta}-r)'[R\\widehat{Avar(\\widehat{\\beta})}R']^{-1}   (R\\widehat{\\beta}-r)$\n",
    "\n",
    ", where, given the above $H_0$, \n",
    "\n",
    "$R=[1 \\quad 1]$\n",
    "\n",
    "$r=1$\n",
    "\n",
    "This statistic can be shown [DO WE HAVE TO SHOW THIS?] to be chi-square distributed under $H_0$, and, hence, $H_0$ can be rejected at level $\\alpha$ if $W>(1-\\alpha)$-quantile of $\\chi_Q^2$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wald test statistic: 69.8893\n",
      "Critical value at the 5% level: 3.8415\n",
      "Critical value at the 1% level: 6.6349\n",
      "Critical value at the 0.001% level: 19.5114\n"
     ]
    }
   ],
   "source": [
    "R=np.array([[1,1]])\n",
    "r=1\n",
    "b_hat = fe_result['b_hat']\n",
    "cov=fe_result['cov']\n",
    "\n",
    "W=(R @ b_hat - r).T*(R @ cov @ R.T)**(-1)*(R @ b_hat - r)\n",
    "\n",
    "print(f'Wald test statistic: {W[0,0]:.4f}')\n",
    "\n",
    "\n",
    "chi_2_05 = chi2.ppf(1 - 0.05, df=1)  # degrees of freedom = 1\n",
    "chi_2_01 = chi2.ppf(1 - 0.01, df=1)  # degrees of freedom = 1\n",
    "chi_2_00001 = chi2.ppf(1 - 0.00001, df=1)  # degrees of freedom = 1\n",
    "print(f'Critical value at the 5% level: {chi_2_05:.4f}')\n",
    "print(f'Critical value at the 1% level: {chi_2_01:.4f}')\n",
    "print(f'Critical value at the 0.001% level: {chi_2_00001:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we reject $H_0$ at a significance level of 0.001%, and conclude that the production does not exhibit constant returns to scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_'></a>[Conclusion](#toc5_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
