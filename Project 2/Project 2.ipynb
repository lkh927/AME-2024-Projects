{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project II: Economic Growth \n",
    "\n",
    "This notebook will help you getting started with analyzing the growth dataset, `growth.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy.stats import norm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Project_2 import *\n",
    "print(f'The data contains {dat.shape[0]} rows (countries) and {dat.shape[1]} columns (variables).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.plot.scatter(x='lgdp_initial', y='gdp_growth', ylabel='GDP growth rate', xlabel='Log of initial GDP, 1970');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "sns.scatterplot(x='lgdp_initial', y='gdp_growth', data=dat, hue='pdivhmi');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-inspection\n",
    "We begin by counting the number of observations for each variable, conditional on 'gdp_growth' and 'lgdp_initial' being non-missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data = filter_data(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collection of variables\n",
    "In order to ease the following analysis, we group ALL the given variables into subcategories. Based on our data-inspection we exclude a range of variables from the analysis. These are grouped in 'vv_excluded'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the variables we will need for further analysis\n",
    "vv_outcome, vv_key, vv_excluded, vv_all = group_data(dat)\n",
    "\n",
    "list_of_lists = vv_all.values()\n",
    "vv_all['all'] = [v for sublist in list_of_lists for v in sublist]\n",
    "\n",
    "print(f'Variables in total: {len(vv_all[\"all\"]+vv_key+vv_outcome+vv_excluded)}')\n",
    "print(f'We include {len(vv_all[\"all\"])} control variables in total.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representativity of choosen variables\n",
    "We check how many observations have non-missing values for ALL the included 66 variables (our two key variables and 64 control variables). We compare this to the corresponding number of observations if all variables (except the two key variables) are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_var = vv_outcome + vv_key\n",
    "all_included = vv_all['all'] + vv_outcome + vv_key\n",
    "\n",
    "non_missing_key_var = dat[key_var].notnull().all(axis=1).sum()\n",
    "print(f'Non-missing values in key variables: {non_missing_key_var}')\n",
    "\n",
    "non_missing_all_included = dat[all_included].notnull().all(axis=1).sum()\n",
    "print(f'Non-missing values in all included variables: {non_missing_all_included}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then check how the observations with non-missing values are distributed across the different geographic regions to get an idea about how representative the remaining observations are. We derive this geographic distribution for all observations ('All_share'), those observations with non-missing values for our key variables ('Key_share'), and those with non-missing values for all the included variables ('Included_share')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['africa', 'americas', 'asia', 'europe', 'oceania']\n",
    "table = investigate_data(regions, dat, vv_outcome, vv_key, vv_all)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that the included variables resemble the geographic distribution of the full data set to a reasonable extent, i.e. there there is no extreme regional bias in our included variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for analysis\n",
    "We create a new data set consisting only of the non-missing observations and the included variables. We add a constant to the data (mainly relevant for OLS analysis), and base our analysis on this new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "# convenient to keep a column of ones in the dataset\n",
    "dat['constant'] = np.ones((dat.shape[0],))\n",
    "vv_constant = ['constant']\n",
    "print(dat.shape)\n",
    "\n",
    "included_rows = dat[vv_outcome + vv_key + vv_all['all']].notnull().all(axis=1)\n",
    "data = dat[included_rows]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[vv_all['all'] + vv_outcome + vv_key + vv_constant]\n",
    "print(data.shape)\n",
    "print(f'There are {data.isnull().sum().sum()} missing observations in the data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = data[vv_outcome].squeeze() #*100 to get it in percentage and not decimals\n",
    "y0 = data[vv_key].squeeze()\n",
    "Z_basic = data[vv_all['all']]\n",
    "Z = PolynomialFeatures(1, include_bias=False).fit_transform(Z_basic)\n",
    "\n",
    "X = np.column_stack((y0,Z))\n",
    "N = X.shape[0]\n",
    "\n",
    "def standardize(X):\n",
    "    X_stan = (X - np.mean(X, axis=0))/np.std(X, axis=0, ddof=1)\n",
    "    return X_stan\n",
    "\n",
    "# Standardize data\n",
    "X_tilde = standardize(X)\n",
    "Z_tilde = standardize(Z)\n",
    "y0_tilde = standardize(y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with X_names as the index\n",
    "Z_names = Z_basic.columns\n",
    "X_names = Z_names.insert(0, y0.name)\n",
    "print(X_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS estimation\n",
    "NOTE: Using \"original\" variables (not standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an matrix with y0 and a constant for simple OLS\n",
    "simple_y0 = np.column_stack((np.ones(N),y0))\n",
    "simple_g = np.array(g).reshape(-1,1)\n",
    "\n",
    "#3. Run OLS\n",
    "betas_simpleOLS = la.inv(simple_y0.T @ simple_y0) @ simple_y0.T @ simple_g\n",
    "pd.DataFrame(betas_simpleOLS, index=['constant', 'lgdp_initial'], columns=['gdp_growth'])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: It is not possible to use all the included variables with OLS as the rank condition is broken when p>n (as is the case here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding more controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we need a matrix of all control variables and a constant\n",
    "X_OLS = np.column_stack((np.ones(N), X))\n",
    "g_OLS = np.array(g).reshape(-1,1)\n",
    "\n",
    "betas_OLS = la.inv(X_OLS.T @ X_OLS) @ X_OLS.T @ g_OLS\n",
    "\n",
    "#checking the rank condition\n",
    "K = X_OLS.shape[1]\n",
    "assert np.linalg.matrix_rank(X) == X.shape[1], f'X does not have full rank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = vv_constant + vv_key + vv_all['all']\n",
    "\n",
    "pd.DataFrame({'Î²': betas_OLS[:,0]}, index=xs).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on BRT penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-single Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Calculate BRT penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function that calculates BRT.\n",
    "def BRT(X_tilde,g):\n",
    "    \n",
    "    (N, p) = X_tilde.shape\n",
    "    sigma = np.std(g, ddof=1)\n",
    "    c = 1.1\n",
    "    alpha = 0.05\n",
    "    penalty_BRT= (c * sigma) / np.sqrt(N) * norm.ppf(1 - alpha / (2*p))\n",
    "\n",
    "    return penalty_BRT\n",
    "\n",
    "penalty_BRT = BRT(X_tilde,g)\n",
    "print(\"lambda_BRT =\",penalty_BRT.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Lasso g using y0 and Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implied estimates and selection\n",
    "fit_BRTgx = Lasso(penalty_BRT, max_iter=10000).fit(X_tilde,g)\n",
    "coeff_BRTgx = fit_BRTgx.coef_\n",
    "intercept_BRTgx = fit_BRTgx.intercept_\n",
    "\n",
    "print('Intercept/constant: ', np.round(intercept_BRTgx,3))\n",
    "print('Coefficients: ', np.round(coeff_BRTgx,3))\n",
    "Z_J_BRTgx = Z[:,coeff_BRTgx[1:]!=0] # Note: We use Z and not Z_stan\n",
    "\n",
    "# Display number of variables in Z_J\n",
    "print(\"The number of variables in Z_J is {}\".format(Z_J_BRTgx.shape[1]))\n",
    "selected_variables_BRTgx = (coeff_BRTgx != 0)\n",
    "print('Selected varriables: ', X_names[selected_variables_BRTgx].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Regress g using y0 and Z_J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant to X\n",
    "xx = np.column_stack((np.ones(N),y0,Z_J_BRTgx))\n",
    "yy = np.array(g).reshape(-1,1)\n",
    "\n",
    "# Calculate OLS estimate\n",
    "coefs_BRT_PSL = la.inv(xx.T@xx)@xx.T@yy\n",
    "\n",
    "#print the coefficients\n",
    "pd.DataFrame(coefs_BRT_PSL, index=['constant', 'lgdp_initial'], columns=['gdp_growth']) #same as for the simple OLS above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the 95 % confidence interval for ${\\beta}_{y0}$ (BRT_PSL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate variance\n",
    "res_BRT_PSL = yy - xx@coefs_BRT_PSL\n",
    "SSR_BRT_PSL = res_BRT_PSL.T@res_BRT_PSL\n",
    "sigma2_BRT_PSL = SSR_BRT_PSL/(N-xx.shape[1])\n",
    "var_BRT_PSL = sigma2_BRT_PSL*la.inv(xx.T@xx)\n",
    "\n",
    "# Calculate standard errors\n",
    "se_BRT_PSL = np.sqrt(np.diagonal(var_BRT_PSL)).reshape(-1, 1)\n",
    "se_BRT_PSL=se_BRT_PSL[1][0]\n",
    "\n",
    "# Display standard error\n",
    "print(\"se_BRT_PSL = \",se_BRT_PSL.round(5))\n",
    "\n",
    "# Calculate the z statistic that corresponds to the 95% confidence interval of a two-sided test\n",
    "q = norm.ppf(1-0.025)\n",
    "\n",
    "# Calculate confidence interval\n",
    "CI_low_BRT_PSL  = coefs_BRT_PSL[1][0]-q*se_BRT_PSL\n",
    "CI_high_BRT_PSL = coefs_BRT_PSL[1][0]+q*se_BRT_PSL\n",
    "\n",
    "# Display confidence interval\n",
    "print(\"Confidence interval for Î²_y0 (BRT_PSL) = \",(CI_low_BRT_PSL.round(5),CI_high_BRT_PSL.round(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion (BRT_PSL): data is not consistent with beta convergence (${\\beta}_{y0}$ is insignificant)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-double Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 & 2: Same as for Post-single Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Lasso D using Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty_BRTy0z = BRT(Z_tilde, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso\n",
    "fit_BRTy0z = Lasso(penalty_BRTy0z, max_iter=10000).fit(Z_tilde, y0)\n",
    "coeff_BRTy0z=fit_BRTy0z.coef_\n",
    "intercept_BRTy0z = fit_BRTy0z.intercept_\n",
    "\n",
    "print('Intercept/constant: ', np.round(intercept_BRTy0z,5))\n",
    "print('Coefficients: ', np.round(coeff_BRTy0z,5))\n",
    "\n",
    "selected_variables_BRTy0z = (coeff_BRTy0z != 0)\n",
    "print('Selected varriables: ', Z_names[selected_variables_BRTy0z].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Estimate ${\\beta}_{y0}$ (called 'alpha' in the slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "res_BRTgx = g - fit_BRTgx.predict(X_tilde)\n",
    "res_BRTgxz = res_BRTgx + y0_tilde*coeff_BRTgx[0]\n",
    "res_BRTy0z=y0-fit_BRTy0z.predict(Z_tilde)\n",
    "\n",
    "# Calculate beta_y0\n",
    "num = res_BRTy0z@res_BRTgxz\n",
    "denom = res_BRTy0z@y0\n",
    "coef_BRT_PDL = num/denom\n",
    "\n",
    "# Display beta_y0\n",
    "print(\"Coefficient for Î²_y0 (BRT_PDL) = \",coef_BRT_PDL.round(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the 95 % confidence interval for ${\\beta}_{y0}$ (BRT_PDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variance    \n",
    "num = res_BRTy0z**2@res_BRTgx**2/N\n",
    "denom = (res_BRTy0z.T@res_BRTy0z/N)**2\n",
    "sigma2_BRT_PDL = num/denom\n",
    "\n",
    "# Calculate standard error\n",
    "se_BRT_PDL = np.sqrt(sigma2_BRT_PDL/N)\n",
    "\n",
    "# Display standard error\n",
    "print(\"se_BRT_PDL = \",se_BRT_PDL.round(5))\n",
    "\n",
    "# Calculate the z statistic that corresponds to the 95% confidence interval of a two-sided test\n",
    "q = norm.ppf(1-0.025)\n",
    "\n",
    "# Calculate confidence interval\n",
    "CI_low_BRT_PDL  = coef_BRT_PDL-q*se_BRT_PDL\n",
    "CI_high_BRT_PDL = coef_BRT_PDL+q*se_BRT_PDL\n",
    "\n",
    "# Display confidence interval\n",
    "print(\"Confidence interval for Î²_y0 (BRT_PDL) = \",(CI_low_BRT_PDL.round(5),CI_high_BRT_PDL.round(5)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion (BRT_PDL): data is not consistent with beta convergence (${\\beta}_{y0}$ is insignificant)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on BCCH penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-single Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Calculate BCCH penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCCH(X_tilde,g):\n",
    "\n",
    "    # BCCH pilot penalty\n",
    "    n,p = X.shape\n",
    "    c = 1.1\n",
    "    alpha = 0.05\n",
    "    gXscale = (np.max((X_tilde.T ** 2) @ ((g-np.mean(g)) ** 2) / n)) ** 0.5\n",
    "    penalty_pilot = c / np.sqrt(n) * norm.ppf(1-alpha/(2*p)) * gXscale # Note: Have divided by 2 due to Python definition of Lasso\n",
    "    \n",
    "    #Create predicted value using Lasso \n",
    "    pred = Lasso(alpha=penalty_pilot).fit(X_tilde,g).predict(X_tilde)\n",
    "\n",
    "    # Updated penalty\n",
    "    eps = g - pred #eps: epsilon/residuals \n",
    "    epsXscale = (np.max((X_tilde.T ** 2) @ (eps ** 2) / n)) ** 0.5\n",
    "    penalty_BCCH = c / np.sqrt(n) * norm.ppf(1-alpha/(2*p))*epsXscale\n",
    "\n",
    "    return penalty_BCCH\n",
    "\n",
    "penalty_BCCH = BCCH(X_tilde,g)\n",
    "print(\"lambda_BCCH =\",penalty_BCCH.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Lasso g using y0 and Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implied estimates and selection\n",
    "fit_BCCHgx = Lasso(penalty_BCCH, max_iter=10000).fit(X_tilde,g)\n",
    "coeff_BCCHgx = fit_BCCHgx.coef_\n",
    "intercept_BCCHgx = fit_BCCHgx.intercept_\n",
    "\n",
    "print('Intercept/constant: ', np.round(intercept_BCCHgx,3))\n",
    "print('Coefficients: ', np.round(coeff_BCCHgx,3))\n",
    "Z_J_BCCHgx = Z[:,coeff_BCCHgx[1:]!=0] # Note: We use Z and not Z_stan\n",
    "\n",
    "# Display number of variables in Z_J\n",
    "print(\"The number of variables in Z_J is {}\".format(Z_J_BCCHgx.shape[1]))\n",
    "selected_variables_BCCHgx = (coeff_BCCHgx != 0)\n",
    "print('Selected varriables: ', X_names[selected_variables_BCCHgx].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 and 4 will yield the same result as for BRT_PSL, as BCCH_PSL return the same Z_J (containing no control variables) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion (BCCH_PSL): data is not consistent with beta convergence (${\\beta}_{y0}$ is insignificant)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-double Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 & 2: Same as for Post-single Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Lasso D using Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty_BCCHy0z = BCCH(Z_tilde, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso\n",
    "fit_BCCHy0z = Lasso(penalty_BCCHy0z, max_iter=10000).fit(Z_tilde, y0)\n",
    "coeff_BCCHy0z=fit_BCCHy0z.coef_\n",
    "intercept_BCCHy0z = fit_BCCHy0z.intercept_\n",
    "\n",
    "print('Intercept/constant: ', np.round(intercept_BCCHy0z,5))\n",
    "print('Coefficients: ', np.round(coeff_BCCHy0z,5))\n",
    "\n",
    "selected_variables_BCCHy0z = (coeff_BCCHy0z != 0)\n",
    "print('Selected varriables: ', Z_names[selected_variables_BCCHy0z].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Estimate ${\\beta}_{y0}$ (called 'alpha' in the slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "res_BCCHgx = g - fit_BCCHgx.predict(X_tilde)\n",
    "res_BCCHgxz = res_BCCHgx + y0_tilde*coeff_BCCHgx[0]\n",
    "res_BCCHy0z=y0-fit_BCCHy0z.predict(Z_tilde)\n",
    "\n",
    "# Calculate beta_y0\n",
    "num = res_BCCHy0z@res_BCCHgxz\n",
    "denom = res_BCCHy0z@y0\n",
    "coef_BCCH_PDL = num/denom\n",
    "\n",
    "# Display beta_y0\n",
    "print(\"Coefficient for Î²_y0 (BCCH_PDL) = \",coef_BCCH_PDL.round(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the 95 % confidence interval for ${\\beta}_{y0}$ (BCCH_PDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variance    \n",
    "num = res_BCCHy0z**2@res_BCCHgx**2/N\n",
    "denom = (res_BCCHy0z.T@res_BCCHy0z/N)**2\n",
    "sigma2_BCCH_PDL = num/denom\n",
    "\n",
    "# Calculate standard error\n",
    "se_BCCH_PDL = np.sqrt(sigma2_BCCH_PDL/N)\n",
    "\n",
    "# Display standard error\n",
    "print(\"se_BCCH_PDL = \",se_BCCH_PDL.round(5))\n",
    "\n",
    "# Calculate the z statistic that corresponds to the 95% confidence interval of a two-sided test\n",
    "q = norm.ppf(1-0.025)\n",
    "\n",
    "# Calculate confidence interval\n",
    "CI_low_BCCH_PDL  = coef_BCCH_PDL-q*se_BCCH_PDL\n",
    "CI_high_BCCH_PDL = coef_BCCH_PDL+q*se_BCCH_PDL\n",
    "\n",
    "# Display confidence interval\n",
    "print(\"Confidence interval for Î²_y0 (BCCH_PDL) = \",(CI_low_BCCH_PDL.round(5),CI_high_BCCH_PDL.round(5)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion (BCCH_PDL): data is not consistent with beta convergence (${\\beta}_{y0}$ is insignificant)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 2 (based on dataset with fewer variables / more observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for analysis\n",
    "First we create a dataset (data2) consisting of those observations which have non-missing values for gdp_growth, lgdp_initial and investment_rate (these variables are explictly mentioned in the assignment text).\n",
    "We then subset data2 such that it include only variables with zero missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_rows2 = dat[vv_outcome + vv_key + ['investment_rate'] ].notnull().all(axis=1)\n",
    "data2 = dat[included_rows2]\n",
    "\n",
    "data2 = data2.dropna(axis=1)\n",
    "\n",
    "print(f'The number of observations left in data2 is {data2.shape[0]}.')\n",
    "print(f'The number of variables with no missing values is {data2.shape[1]}.')\n",
    "print(f'The remaining variables are: {data2.columns.to_list()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = data2[vv_outcome].squeeze() #*100 to get it in percentage and not decimals\n",
    "y0 = data2[vv_key].squeeze()\n",
    "Z_basic = data2.drop([\"gdp_growth\", \"lgdp_initial\",  # Drop outcome and key explanatory variable\n",
    "                      \"code\", \"constant\", \"gdp_initial\", \"lpop_initial\", \"pother\", \"europe\"], axis=1) # Drop irrelevant/perfectly correlated/reference variables\n",
    "Z = PolynomialFeatures(1, include_bias=False).fit_transform(Z_basic)\n",
    "X = np.column_stack((y0,Z))\n",
    "N = X.shape[0]\n",
    "\n",
    "def standardize(X):\n",
    "    X_stan = (X - np.mean(X, axis=0))/np.std(X, axis=0, ddof=1)\n",
    "    return X_stan\n",
    "\n",
    "# Standardize data\n",
    "X_tilde = standardize(X)\n",
    "Z_tilde = standardize(Z)\n",
    "y0_tilde = standardize(y0)\n",
    "\n",
    "print(f'The number of variables in Z is {Z.shape[1]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with X_names as the index\n",
    "Z_names = Z_basic.columns\n",
    "X_names = Z_names.insert(0, y0.name)\n",
    "print(X_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on BRT penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-single Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Calculate BRT penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function that calculates BRT.\n",
    "def BRT(X_tilde,g):\n",
    "    \n",
    "    (N, p) = X_tilde.shape\n",
    "    sigma = np.std(g, ddof=1)\n",
    "    c = 1.1\n",
    "    alpha = 0.05\n",
    "    penalty_BRT= (c * sigma) / np.sqrt(N) * norm.ppf(1 - alpha / (2*p))\n",
    "\n",
    "    return penalty_BRT\n",
    "\n",
    "penalty_BRT = BRT(X_tilde,g)\n",
    "print(\"lambda_BRT =\",penalty_BRT.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Lasso g using y0 and Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implied estimates and selection\n",
    "fit_BRTgx = Lasso(penalty_BRT, max_iter=10000).fit(X_tilde,g)\n",
    "coeff_BRTgx = fit_BRTgx.coef_\n",
    "intercept_BCCHgx = fit_BCCHgx.intercept_\n",
    "\n",
    "print('Intercept/constant: ', np.round(intercept_BCCHgx,3))\n",
    "print('Coefficients: ', np.round(coeff_BRTgx,3))\n",
    "Z_J_BRTgx = Z[:,coeff_BRTgx[1:]!=0] # Note: We use Z and not Z_stan\n",
    "\n",
    "# Display number of variables in Z_J\n",
    "print(\"The number of variables in Z_J is {}\".format(Z_J_BRTgx.shape[1]))\n",
    "selected_variables_BRTgx = (coeff_BRTgx != 0)\n",
    "print('Selected varriables: ', X_names[selected_variables_BRTgx].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Regress g using y0 and Z_J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant to X\n",
    "xx = np.column_stack((np.ones(N),y0,Z_J_BRTgx))\n",
    "yy = np.array(g).reshape(-1,1)\n",
    "\n",
    "# Calculate OLS estimate\n",
    "coefs_BRT_PSL = la.inv(xx.T@xx)@xx.T@yy\n",
    "\n",
    "#print the coefficients\n",
    "pd.DataFrame(coefs_BRT_PSL, index=[['constant', 'lgdp_initial']+X_names[selected_variables_BRTgx].to_list()], columns=['gdp_growth']) #same as for the simple OLS above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the 95 % confidence interval for ${\\beta}_{y0}$ (BRT_PSL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate variance\n",
    "res_BRT_PSL = yy - xx@coefs_BRT_PSL\n",
    "SSR_BRT_PSL = res_BRT_PSL.T@res_BRT_PSL\n",
    "sigma2_BRT_PSL = SSR_BRT_PSL/(N-xx.shape[1])\n",
    "var_BRT_PSL = sigma2_BRT_PSL*la.inv(xx.T@xx)\n",
    "\n",
    "# Calculate standard errors\n",
    "se_BRT_PSL = np.sqrt(np.diagonal(var_BRT_PSL)).reshape(-1, 1)\n",
    "se_BRT_PSL=se_BRT_PSL[1][0]\n",
    "\n",
    "# Display standard error\n",
    "print(\"se_BRT_PSL = \",se_BRT_PSL.round(5))\n",
    "\n",
    "# Calculate the z statistic that corresponds to the 95% confidence interval of a two-sided test\n",
    "q = norm.ppf(1-0.025)\n",
    "\n",
    "# Calculate confidence interval\n",
    "CI_low_BRT_PSL  = coefs_BRT_PSL[1][0]-q*se_BRT_PSL\n",
    "CI_high_BRT_PSL = coefs_BRT_PSL[1][0]+q*se_BRT_PSL\n",
    "\n",
    "# Display confidence interval\n",
    "print(\"Confidence interval for Î²_y0 (BRT_PSL) = \",(CI_low_BRT_PSL.round(5),CI_high_BRT_PSL.round(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion (BRT_PSL): data is not consistent with beta convergence (${\\beta}_{y0}$ is insignificant)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-double Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 & 2: Same as for Post-single Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Lasso D using Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty_BRTy0z = BRT(Z_tilde, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso\n",
    "fit_BRTy0z = Lasso(penalty_BRTy0z, max_iter=10000).fit(Z_tilde, y0)\n",
    "coeff_BRTy0z=fit_BRTy0z.coef_\n",
    "intercept_BRTy0z = fit_BRTy0z.intercept_\n",
    "\n",
    "print('Intercept/constant: ', np.round(intercept_BRTy0z,5))\n",
    "print('Coefficients: ', np.round(coeff_BRTy0z,5))\n",
    "\n",
    "selected_variables_BRTy0z = (coeff_BRTy0z != 0)\n",
    "print('Selected varriables: ', Z_names[selected_variables_BRTy0z].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Estimate ${\\beta}_{y0}$ (called 'alpha' in the slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "res_BRTgx = g - fit_BRTgx.predict(X_tilde)\n",
    "res_BRTgxz = res_BRTgx + y0_tilde*coeff_BRTgx[0]\n",
    "res_BRTy0z=y0-fit_BRTy0z.predict(Z_tilde)\n",
    "\n",
    "# Calculate beta_y0\n",
    "num = res_BRTy0z@res_BRTgxz\n",
    "denom = res_BRTy0z@y0\n",
    "coef_BRT_PDL = num/denom\n",
    "\n",
    "# Display beta_y0\n",
    "print(\"Coefficient for Î²_y0 (BRT_PDL) = \",coef_BRT_PDL.round(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the 95 % confidence interval for ${\\beta}_{y0}$ (BRT_PDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variance    \n",
    "num = res_BRTy0z**2@res_BRTgx**2/N\n",
    "denom = (res_BRTy0z.T@res_BRTy0z/N)**2\n",
    "sigma2_BRT_PDL = num/denom\n",
    "\n",
    "# Calculate standard error\n",
    "se_BRT_PDL = np.sqrt(sigma2_BRT_PDL/N)\n",
    "\n",
    "# Display standard error\n",
    "print(\"se_BRT_PDL = \",se_BRT_PDL.round(5))\n",
    "\n",
    "# Calculate the z statistic that corresponds to the 95% confidence interval of a two-sided test\n",
    "q = norm.ppf(1-0.025)\n",
    "\n",
    "# Calculate confidence interval\n",
    "CI_low_BRT_PDL  = coef_BRT_PDL-q*se_BRT_PDL\n",
    "CI_high_BRT_PDL = coef_BRT_PDL+q*se_BRT_PDL\n",
    "\n",
    "# Display confidence interval\n",
    "print(\"Confidence interval for Î²_y0 (BRT_PDL) = \",(CI_low_BRT_PDL.round(5),CI_high_BRT_PDL.round(5)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion (BRT_PDL): data is not consistent with beta convergence (${\\beta}_{y0}$ is insignificant)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on BCCH penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-single Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Calculate BCCH penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCCH(X_tilde,g):\n",
    "\n",
    "    # BCCH pilot penalty\n",
    "    n,p = X.shape\n",
    "    c = 1.1\n",
    "    alpha = 0.05\n",
    "    gXscale = (np.max((X_tilde.T ** 2) @ ((g-np.mean(g)) ** 2) / n)) ** 0.5\n",
    "    penalty_pilot = c / np.sqrt(n) * norm.ppf(1-alpha/(2*p)) * gXscale # Note: Have divided by 2 due to Python definition of Lasso\n",
    "    \n",
    "    #Create predicted value using Lasso \n",
    "    pred = Lasso(alpha=penalty_pilot).fit(X_tilde,g).predict(X_tilde)\n",
    "\n",
    "    # Updated penalty\n",
    "    eps = g - pred #eps: epsilon/residuals \n",
    "    epsXscale = (np.max((X_tilde.T ** 2) @ (eps ** 2) / n)) ** 0.5\n",
    "    penalty_BCCH = c / np.sqrt(n) * norm.ppf(1-alpha/(2*p))*epsXscale\n",
    "\n",
    "    return penalty_BCCH\n",
    "\n",
    "penalty_BCCH = BCCH(X_tilde,g)\n",
    "print(\"lambda_BCCH =\",penalty_BCCH.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Lasso g using y0 and Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implied estimates and selection\n",
    "fit_BCCHgx = Lasso(penalty_BCCH, max_iter=10000).fit(X_tilde,g)\n",
    "coeff_BCCHgx = fit_BCCHgx.coef_\n",
    "intercept_BCCHgx = fit_BCCHgx.intercept_\n",
    "\n",
    "print('Intercept/constant: ', np.round(intercept_BCCHgx,3))\n",
    "print('Coefficients: ', np.round(coeff_BCCHgx,3))\n",
    "Z_J_BCCHgx = Z[:,coeff_BCCHgx[1:]!=0] # Note: We use Z and not Z_stan\n",
    "\n",
    "# Display number of variables in Z_J\n",
    "print(\"The number of variables in Z_J is {}\".format(Z_J_BCCHgx.shape[1]))\n",
    "selected_variables_BCCHgx = (coeff_BCCHgx != 0)\n",
    "print('Selected varriables: ', X_names[selected_variables_BCCHgx].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 and 4 will yield the same result as for BRT_PSL, as BCCH_PSL return the same Z_J (containing no control variables) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion (BCCH_PSL): data is not consistent with beta convergence (${\\beta}_{y0}$ is insignificant)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-double Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 & 2: Same as for Post-single Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Lasso D using Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty_BCCHy0z = BCCH(Z_tilde, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso\n",
    "fit_BCCHy0z = Lasso(penalty_BCCHy0z, max_iter=10000).fit(Z_tilde, y0)\n",
    "coeff_BCCHy0z=fit_BCCHy0z.coef_\n",
    "intercept_BCCHy0z = fit_BCCHy0z.intercept_\n",
    "\n",
    "print('Intercept/constant: ', np.round(intercept_BCCHy0z,5))\n",
    "print('Coefficients: ', np.round(coeff_BCCHy0z,5))\n",
    "\n",
    "selected_variables_BCCHy0z = (coeff_BCCHy0z != 0)\n",
    "print('Selected varriables: ', Z_names[selected_variables_BCCHy0z].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Estimate ${\\beta}_{y0}$ (called 'alpha' in the slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "res_BCCHgx = g - fit_BCCHgx.predict(X_tilde)\n",
    "res_BCCHgxz = res_BCCHgx + y0_tilde*coeff_BCCHgx[0]\n",
    "res_BCCHy0z=y0-fit_BCCHy0z.predict(Z_tilde)\n",
    "\n",
    "# Calculate beta_y0\n",
    "num = res_BCCHy0z@res_BCCHgxz\n",
    "denom = res_BCCHy0z@y0\n",
    "coef_BCCH_PDL = num/denom\n",
    "\n",
    "# Display beta_y0\n",
    "print(\"Coefficient for Î²_y0 (BCCH_PDL) = \",coef_BCCH_PDL.round(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the 95 % confidence interval for ${\\beta}_{y0}$ (BCCH_PDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variance    \n",
    "num = res_BCCHy0z**2@res_BCCHgx**2/N\n",
    "denom = (res_BCCHy0z.T@res_BCCHy0z/N)**2\n",
    "sigma2_BCCH_PDL = num/denom\n",
    "\n",
    "# Calculate standard error\n",
    "se_BCCH_PDL = np.sqrt(sigma2_BCCH_PDL/N)\n",
    "\n",
    "# Display standard error\n",
    "print(\"se_BCCH_PDL = \",se_BCCH_PDL.round(5))\n",
    "\n",
    "# Calculate the z statistic that corresponds to the 95% confidence interval of a two-sided test\n",
    "q = norm.ppf(1-0.025)\n",
    "\n",
    "# Calculate confidence interval\n",
    "CI_low_BCCH_PDL  = coef_BCCH_PDL-q*se_BCCH_PDL\n",
    "CI_high_BCCH_PDL = coef_BCCH_PDL+q*se_BCCH_PDL\n",
    "\n",
    "# Display confidence interval\n",
    "print(\"Confidence interval for Î²_y0 (BCCH_PDL) = \",(CI_low_BCCH_PDL.round(5),CI_high_BCCH_PDL.round(5)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion (BCCH_PDL): data is not consistent with beta convergence (${\\beta}_{y0}$ is insignificant)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
