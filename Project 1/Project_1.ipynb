{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project 1: Linear Panel Data and Production Technology**\n",
    "\n",
    "By Emma Knippel, Anna Abildskov and Tobias Rønn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**\n",
    "\n",
    "* [Setup](#toc0_)\n",
    "\n",
    "* [Read and clean data](#toc1_)\n",
    "\n",
    "* [FE estimation of $\\beta_K$ and $\\beta_L$](#toc2_)    \n",
    "\n",
    "* [FD estimation of $\\beta_K$ and $\\beta_L$](#toc3_)\n",
    "\n",
    "* [RE estimation of $\\beta_K$ and $\\beta_L$](#toc4_)\n",
    "\n",
    "* [Hausman test](#toc5_)\n",
    "\n",
    "* [Test for strict exogeneity](#toc6_)\n",
    "\n",
    "* [Test for constant returns to scale](#toc7_)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc0_'><a>[Setup](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2\n",
    "\n",
    "#Supress Future Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#Import our py-file\n",
    "import Project_1 as pf\n",
    "\n",
    "# autoreload modules when code is run\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_'></a>[Read and clean data](#toc1_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains `N = 441` firms observed over `T = 12` years, 1968-1979. There variables are: \n",
    "* `lcap`: Log of capital stock, $k_{it}$ \n",
    "* `lemp`: log of employment, $\\ell_{it}$ \n",
    "* `ldsa`: log of deflated sales, $y_{it}$\n",
    "* `year`: the calendar year of the observation, `year` $ = 1968, ..., 1979$, \n",
    "* `firmid`: anonymized indicator variable for the firm, $i = 1, ..., N$, with $N=441$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data and dropping all the even years, leaving us with only odd year-observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_years = pd.read_csv('firms.csv')\n",
    "data = df_all_years[df_all_years.year % 2 != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting data to numpy format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains data for 441 firms over 6 odd years\n"
     ]
    }
   ],
   "source": [
    "N = data.firmid.unique().size\n",
    "T = data.year.unique().size\n",
    "print(f'Data contains data for {N} firms over {T} odd years')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting data to numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.ldsa.values.reshape((N*T,1))\n",
    "l = data.lemp.values.reshape((N*T,1))\n",
    "k = data.lcap.values.reshape((N*T,1))\n",
    "ones = np.ones((N*T, 1))\n",
    "X = np.hstack([ones, l, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.        -0.241278   0.9252139]\n",
      " [ 1.        -0.317875   0.8430977]\n",
      " [ 1.        -0.30135    0.7943461]\n",
      " ...\n",
      " [ 1.        -0.956662  -1.00608  ]\n",
      " [ 1.        -0.672649  -0.719267 ]\n",
      " [ 1.        -0.567195  -0.522616 ]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating label-vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_y = 'Log of deflated sales'\n",
    "label_x = ['Constant', 'Log of employment', 'Log of capital stock']\n",
    "label_x_fe = ['Log of employment', 'Log of capital stock']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_'></a>[FE estimation of $\\beta_K$ and $\\beta_L$](#toc2_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of our project, we have decided to use the Fixed-Effects (FE) estimator to find estimates of $\\beta_K$ and $\\beta_L$. \n",
    "\n",
    "For the FE-estimation, we need to demean our dependent variable and our regressors - to perform a \"within transformation\". We do this by creating a a demeaning matrix, and using it as input in the transformation function from Project_1.py. Here, we create the $Q_T$ demeaning matrix of the form:\n",
    "\n",
    "$$\\mathbf{Q}_T = \\mathbf{I}_T - \\frac{1}{T}{\\mathbf{j}_T}{\\mathbf{j}_T}'\n",
    "    $$\n",
    "$$ = \n",
    "    \\begin{bmatrix}\n",
    "    1-\\frac{1}{T} & -\\frac{1}{T} & \\dots & -\\frac{1}{T}\\\\\n",
    "    -\\frac{1}{T} & 1-\\frac{1}{T} & \\dots & -\\frac{1}{T}\\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "    -\\frac{1}{T} & -\\frac{1}{T} & \\dots & 1-\\frac{1}{T}\n",
    "    \\end{bmatrix}_{T \\times T}\n",
    "$$\n",
    "\n",
    "We use this as input in our transformation function to obtain $(\\ddot{y}_{it}, \\ddot{\\mathbf{x}}_{it})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_T = np.eye(T) - np.tile(1/T, (T, T)) \n",
    "\n",
    "#only include the log of employment and log of capital stock, no constant\n",
    "X_fe = X[:, 1:]\n",
    "\n",
    "y_demean = pf.perm(Q_T, y)\n",
    "x_demean = pf.perm(Q_T, X_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FE estimator is essentially the pooled OLS estimator on our within-transformed variables. It is defined as such:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_{FE} = \n",
    "\\left(\n",
    "    \\sum_{i=1}^{N}\\sum_{t=1}^{T}\\ddot{\\mathbf{x}}'_{it}\\ddot{\\mathbf{x}}_{it}\n",
    "    \\right)^{-1}\n",
    "\\left(\n",
    "    \\sum_{i=1}^{N}\\sum_{t=1}^{T}\\ddot{\\mathbf{x}}'_{it}\\ddot{y}_{it}\n",
    "    \\right)\n",
    "$$\n",
    "\n",
    "Stacked over $t$ and $i$, in matrix form it becomes:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_{FE} = (\\ddot{\\mathbf{X}}'\\ddot{\\mathbf{X}})^{-1}\\ddot{\\mathbf{X}}'\\ddot{\\mathbf{y}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the FE estimator to be consistent, we must make sure that the regression matrix has full rank (FE.2 condition). We check this with our rank-checking function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of transformed x: 2\n",
      "Eigenvalues of transformed x: [28. 99.]\n"
     ]
    }
   ],
   "source": [
    "pf.check_rank(x_demean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have confirmed the demeaned matrix to have full rank, we don't need to adjust it, we can just run the estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Effects\n",
      "Dependent variable: Log of deflated sales\n",
      "\n",
      "                        Beta      Se    t-values\n",
      "--------------------  ------  ------  ----------\n",
      "Log of employment     0.7069  0.0221     32.0114\n",
      "Log of capital stock  0.1424  0.0197      7.2402\n",
      "R² = 0.468\n",
      "σ² = 0.019\n"
     ]
    }
   ],
   "source": [
    "fe_result = pf.estimate(y_demean, x_demean, transform='fe', T=T)\n",
    "pf.print_table((label_y, label_x_fe), fe_result, title=\"Fixed Effects\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_'></a>[FD estimation of $\\beta_K$ and $\\beta_L$](#toc3_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEKST OM FD MATRIX TRANSFORMATION**\n",
    "**TEKST OM RANK CONDITION FOR FD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_T = np.eye(T) - np.eye(T, k=-1)\n",
    "D_T = D_T[1:]\n",
    "\n",
    "#only include the log of employment and log of capital stock, no constant\n",
    "X_re = X[:, 1:]\n",
    "\n",
    "y_diff = pf.perm(D_T, y)\n",
    "x_diff = pf.perm(D_T, X_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of transformed x: 2\n",
      "Eigenvalues of transformed x: [29. 56.]\n"
     ]
    }
   ],
   "source": [
    "pf.check_rank(x_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Differences\n",
      "Dependent variable: Log of deflated sales\n",
      "\n",
      "                        Beta      Se    t-values\n",
      "--------------------  ------  ------  ----------\n",
      "Log of employment     0.7253  0.0248     29.2665\n",
      "Log of capital stock  0.0547  0.0235      2.3307\n",
      "R² = 0.313\n",
      "σ² = 0.022\n"
     ]
    }
   ],
   "source": [
    "fd_result = pf.estimate(y_diff, x_diff, transform ='fd', T=T)\n",
    "\n",
    "pf.print_table((label_y, label_x_fe), fd_result, title=\"First Differences\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_'></a>[Test for strict exogeneity](#toc6_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure the exogeneity conditions for FE and FD hold, we must test this with an exogeneity test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we add a lead variable for both capital and employment (losing data from the last period, so therefore removing the last year for each of them), and then we estimate the model with FE by demeaning the new variables using the transformation matrix above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformation matrix to obtain the leads\n",
    "F_T = np.eye(T, k=1)\n",
    "F_T = F_T[:-1]\n",
    "\n",
    "employment_lead = pf.perm(F_T, X[:, 1].reshape(-1, 1))\n",
    "capital_lead = pf.perm(F_T, X[:, 2].reshape(-1, 1))\n",
    "\n",
    "# Remove the last observed year for every individual\n",
    "I_T = np.eye(T, k=0)\n",
    "I_T = I_T[:-1]\n",
    "\n",
    "x_exo = pf.perm(I_T, X)\n",
    "y_exo = pf.perm(I_T, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the leads to x_exo\n",
    "x_exo = np.hstack([x_exo, employment_lead, capital_lead])\n",
    "\n",
    "# Within transformation of the data\n",
    "Q_T_exo = np.eye(T-1) - np.tile(1/(T-1), (T-1, T-1)) \n",
    "y_exo_demean = pf.perm(Q_T_exo, y_exo)\n",
    "x_exo_demean = pf.perm(Q_T_exo, x_exo)\n",
    "\n",
    "# Select cariables\n",
    "x_exo_demean = np.hstack((x_exo_demean[:, 1:4], x_exo_demean[:, -1].reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exogeneity test\n",
      "Dependent variable: Log of deflated sales\n",
      "\n",
      "                                Beta      Se    t-values\n",
      "----------------------------  ------  ------  ----------\n",
      "Log of employment             0.6247  0.0290     21.5751\n",
      "Log of capital stock          0.0576  0.0253      2.2759\n",
      "Lead of log of employment     0.0418  0.0279      1.5014\n",
      "Lead of log of capital stock  0.1571  0.0296      5.3140\n",
      "R² = 0.462\n",
      "σ² = 0.016\n"
     ]
    }
   ],
   "source": [
    "#Estimate the model\n",
    "exo_test = pf.estimate(y_exo_demean, x_exo_demean, transform='fe', T=T-1)\n",
    "\n",
    "label_exo = label_x_fe + ['Lead of log of employment', 'Lead of log of capital stock']\n",
    "pf.print_table((label_y, label_exo), exo_test, title=\"Exogeneity test\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 4 is different from 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m R \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m cov \u001b[38;5;241m=\u001b[39m exo_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcov\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m pf\u001b[38;5;241m.\u001b[39mwald_test(b_hat, r, R, cov)\n",
      "File \u001b[0;32m~/Desktop/POLIT 9 SEM/Advanced Microeconometrics/Projects/AME-2024-Projects/Project 1/Project_1.py:223\u001b[0m, in \u001b[0;36mwald_test\u001b[0;34m(b_hat, r, R, cov)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwald_test\u001b[39m(b_hat, r, R, cov):\n\u001b[1;32m    212\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Calculates the Wald test for the hypothesis Rb = q. \u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m        float: The Wald test statistic.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m     W \u001b[38;5;241m=\u001b[39m (R \u001b[38;5;241m@\u001b[39m b_hat \u001b[38;5;241m-\u001b[39m r)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m*\u001b[39m(R \u001b[38;5;241m@\u001b[39m cov \u001b[38;5;241m@\u001b[39m R\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m(R \u001b[38;5;241m@\u001b[39m b_hat \u001b[38;5;241m-\u001b[39m r)\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWald test statistic: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mW[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    226\u001b[0m     DF_W \u001b[38;5;241m=\u001b[39m R\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 4 is different from 3)"
     ]
    }
   ],
   "source": [
    "b_hat = exo_test['b_hat']\n",
    "r = 0\n",
    "R = np.array([[0,0,1]]).reshape(1,-1)\n",
    "cov = exo_test['cov']\n",
    "\n",
    "pf.wald_test(b_hat, r, R, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_matrix_test = np.array([0,0,1]).reshape(1,-1)\n",
    "r_target_test = np.array([0]).reshape(1,-1)\n",
    "Avar_beta_test = test_result['cov']\n",
    "beta_hat_test = test_result['b_hat']\n",
    "\n",
    "W_statistic = (R_matrix_test@beta_hat_test - r_target_test).T@(np.linalg.inv(R_matrix_test@Avar_beta_test@R_matrix_test.T))@(R_matrix_test@beta_hat_test-r_target_test)\n",
    "critical_value = chi2.ppf(1 - 0.05, 1)\n",
    "\n",
    "print('This is the test statistic: ', W_statistic)\n",
    "print('This is the critical value: ', critical_value)\n",
    "p_val = 1 - chi2.cdf(W_statistic.item(), 1)\n",
    "\n",
    "print('The p-value is:',p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaTeX table saved to exogeneity_test.tex\n"
     ]
    }
   ],
   "source": [
    "pf.export_to_latex([exo_test], ['Exogeneity test'], [label_exo], filename='exogeneity_test.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_'></a>[RE estimation of $\\beta_K$ and $\\beta_L$](#toc_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RE estimator is based on a \"quasi-demeaning\" of the variables by premultiplying the variable-means by $\\hat{\\lambda}$, which can be estimated by: \n",
    "\n",
    "$$\\hat{\\lambda} \\equiv 1 - \\sqrt{\\frac{\\widehat{\\sigma}_{u}^{2}}{(\\widehat{\\sigma}_{u}^{2} + T\\widehat{\\sigma}_{c}^{2})}}, $$\n",
    "\n",
    "where $\\widehat{\\sigma}_{u}^{2}$ can be estimated from the fixed effects regression, and $\\hat{\\sigma}_{c}^{2}$ can be constructed as  $\\hat{\\sigma}_{c}^{2} = \\hat{\\sigma}_{w}^{2} - \\frac{1}{T}\\hat{\\sigma}_{u}^{2}$. Here $\\hat{\\sigma}_{w}^{2}$ is the error variance from the between estimator (BE), \n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}_{w}^{2} = \\frac{1}{N-K}\\left(\\bar{\\mathbf{y}} - \\mathbf{\\bar{X}}\\hat{\\mathbf{\\beta}}_{BE}\\right)^{\\prime}\\left(\\bar{\\mathbf{y}} - \\mathbf{\\bar{X}}\\hat{\\mathbf{\\beta}}_{BE}\\right),\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\beta}_{BE}$ are the between estimator coefficients.\n",
    "\n",
    "Hence, three steps are required before we can estimate our model with the RE estimator:\n",
    "1) Estimate the model by FE (done above)\n",
    "2) Estimate the model by BE.\n",
    "3) Estimate $\\hat{\\lambda}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Estimating the model by BE**\n",
    "\n",
    "This is based on the transformation matrix $P_T$:\n",
    "\n",
    "$$ \\mathbf{P}_T=\\frac{1}{T}{\\mathbf{j}_T}{\\mathbf{j}_T}'\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "    \\frac{1}{T} & \\frac{1}{T} & \\dots & \\frac{1}{T}\\\\\n",
    "    \\frac{1}{T} & \\frac{1}{T} & \\dots & \\frac{1}{T}\\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "    \\frac{1}{T} & \\frac{1}{T} & \\dots & \\frac{1}{T}\n",
    "    \\end{bmatrix}_{T \\times T}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between Estimator\n",
      "Dependent variable: Log of deflated sales\n",
      "\n",
      "                         Beta      Se    t-values\n",
      "--------------------  -------  ------  ----------\n",
      "Constant              -0.0000  0.0066     -0.0000\n",
      "Log of employment      0.6717  0.0141     47.7252\n",
      "Log of capital stock   0.3160  0.0127     24.9179\n",
      "R² = 0.922\n",
      "σ² = 0.116\n"
     ]
    }
   ],
   "source": [
    "# Transform the data\n",
    "P_T = np.tile(1/T, (T, T)) \n",
    "\n",
    "y_mean = pf.perm(P_T, y)\n",
    "x_mean = pf.perm(P_T, X)\n",
    "\n",
    "# Estimate \n",
    "be_result = pf.estimate(y_mean, x_mean, transform='be', T=T)\n",
    "pf.print_table((label_y, label_x), be_result, title=\"Between Estimator\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Estimating $\\hat{\\lambda}$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda is approximately equal to 0.8356.\n"
     ]
    }
   ],
   "source": [
    "# Calculate lambda (note lambda is a reserved keyword in Python, so we use _lambda instead)\n",
    "sigma2_u = fe_result['sigma2']\n",
    "sigma2_w = be_result['sigma2']\n",
    "sigma2_c = sigma2_w - 1/T * sigma2_u\n",
    "_lambda = 1 - np.sqrt(sigma2_u / (sigma2_u + T*sigma2_c))\n",
    "\n",
    "# Print lambda \n",
    "print(f'Lambda is approximately equal to {_lambda.item():.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an estimate of $\\hat{\\lambda}$, we can estimate the model with the RE estimator. This requires us to quasi-demean our dependent variable and our regressors. We do this by creating a a demeaning matrix, and using it as input in the transformation function from Project_1.py. Here, we create the $\\mathbf{\\hat{C}}_T$ quasi-demeaning matrix of the form:\n",
    "\n",
    "$$\\mathbf{\\hat{C}}_T = \\mathbf{I}_t - \\hat{\\lambda}\\mathbf{P}_t\n",
    "    $$\n",
    "\n",
    "We use this as input in our transformation function to obtain $(\\check{y}_{it}, \\check{\\mathbf{x}}_{it})$, and then estimate the function:\n",
    "\n",
    "$$\\check{y}_{it} = \\mathbf{\\check{x}}_{it}\\boldsymbol{\\beta} + \\check{v}_{it},\\tag{6}$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Effects Estimation\n",
      "Dependent variable: Log of deflated sales\n",
      "\n",
      "                         Beta      Se    t-values\n",
      "--------------------  -------  ------  ----------\n",
      "Constant              -0.0000  0.0164     -0.0000\n",
      "Log of employment      0.7331  0.0180     40.7422\n",
      "Log of capital stock   0.2150  0.0161     13.3153\n",
      "R² = 0.725\n",
      "σ² = 0.019\n"
     ]
    }
   ],
   "source": [
    "# Transform the data\n",
    "C_T = np.eye(T, T) - _lambda * P_T\n",
    "y_re = pf.perm(C_T, y)\n",
    "x_re = pf.perm(C_T, X)\n",
    "\n",
    "# Estimate \n",
    "re_result = pf.estimate(y_re, x_re, transform='re', T=T)\n",
    "pf.print_table((label_y, label_x), re_result, title=\"Random Effects Estimation\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaTeX table saved to regression_table.tex\n"
     ]
    }
   ],
   "source": [
    "col_headers = ['FE', 'FD', 'RE']\n",
    "results_list = [fe_result, fd_result, re_result]\n",
    "var_names_list = [\n",
    "    label_x_fe, # FE variables\n",
    "    label_x_fe, # FD variables\n",
    "    label_x    # RE variables\n",
    "]\n",
    "\n",
    "pf.export_to_latex(results_list, col_headers, var_names_list, filename='regression_table.tex', label_x = label_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_'></a>[Hausman test](#toc5_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hausman test helps us make our final decision on whether to select the FE estimator or the REE estimator. The null hypothesis is that RE.1-3 as well as FE.2 holds, and if this is the case, the RE estimator is asymptotically efficient.\n",
    "\n",
    "Since we already confirmed our rank condition, the null hypothesis will align with RE.1-3, suggesting the asymptotic efficiency of RE. If the null fails, we interpret that as a suggestion of RE.1(b) failing, and thus, RE being inconsistent and not usable for us.\n",
    "\n",
    "So, if the null holds, we select RE. If we reject it, we select FE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hausman test statistic: 78.83\n",
      "The p-value is: 0.00000000 (df=2)\n",
      "Critical value at the 5% level: 5.9915\n",
      "Critical value at the 1% level: 9.2103\n",
      "Critical value at the 0.001% level: 23.0259\n"
     ]
    }
   ],
   "source": [
    "# Unpack\n",
    "b_fe = fe_result['b_hat']\n",
    "b_re = re_result['b_hat']\n",
    "cov_fe = fe_result['cov']\n",
    "cov_re = re_result['cov']\n",
    "\n",
    "# Calculate the test statistic\n",
    "pf.hausman_test(b_fe, b_re, cov_fe, cov_re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we reject $H_0$ at a significance level < 0.001%, and select the FE estimator as our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc7_'></a>[Test for constant returns to scale](#toc7_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Cobb Douglas production technology, yield a constant return to scale if the parameters of the production inputs (i.e. the betas) sum to unity. Specifically, the production technology specified in relation to this assignment, will yield constant returns to scale if $\\beta_K + \\beta_L = 1$. Based on an Wald test, we can test the hypothesis that this is true against the alternative, that it is not true.\n",
    "\n",
    "$$H_0: \\beta_K + \\beta_L = 1$$\n",
    "\n",
    "$$H_1: \\beta_K + \\beta_L \\neq 1$$\n",
    "\n",
    "The general Wald statistic is: \n",
    "\n",
    "$$W \\equiv (R\\widehat{\\beta}-r)'[R\\widehat{Avar(\\widehat{\\beta})}R']^{-1}   (R\\widehat{\\beta}-r)\\$$\n",
    "\n",
    "where, given the above $H_0$, \n",
    "\n",
    "$$R=[1 \\quad 1]$$\n",
    "\n",
    "$$r=1$$\n",
    "\n",
    "This statistic can be shown to be chi-square distributed under $H_0$, and, hence, $H_0$ can be rejected at level $\\alpha$ if $W>(1-\\alpha)$-quantile of $\\chi_Q^2$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wald test statistic: 69.89\n",
      "The p-value is: 0.00000000 (df=1)\n",
      "Critical value at the 5% level: 3.8415\n",
      "Critical value at the 1% level: 6.6349\n",
      "Critical value at the 0.001% level: 19.5114\n"
     ]
    }
   ],
   "source": [
    "b_hat = fe_result['b_hat']\n",
    "r = 1\n",
    "R = np.array([[1,1]])\n",
    "cov = fe_result['cov']\n",
    "\n",
    "pf.wald_test(b_hat, r, R, cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we reject $H_0$ at a significance level = 0.001%, and conclude that the production does not exhibit constant returns to scale."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
